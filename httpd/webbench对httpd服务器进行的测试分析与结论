1.使用webbench的参数-c为2的指数增长，但是在有失败连接数附近再选取一些进行测试 ，-t指定压测时长为10秒对httpd进行的测试																	
  注明：Speed(pages/min,bytes/sec)     Request响应连接数  																	
		     Speed			    Request												
客户端		按每分钟	按每秒		success	failed											
2		468	7862		78	0											
4		78	1313		13	0											
8		1494	25099		249	0											
16		252	4235		42	0											
28		1062	17481		177	0											
29		1086	18246		181	0											
30		1020	17036		169	1											
32		846	14119		140	1											
33		1686	26816		266	15											
34		582	8872		88	9											
35		1788	29653		294	4											
36		714	11995		119	0											
64		1500	23105		241	0											
128		3015	52001		510	8											
130		2910	46305		461	24											
132		3216	52934		526	10											
134		216	2930		29	7											
135		6138	102448		1019	4											
136		3678	58224		581	32											
138		2436	40357		403	3											
140		6	104		1	0	这里误差比较大，猜测可能是之前连接数过多，造成服务器基本无法处理请求										
150		1206	19963		198	3											
160		3174	49399		492	37											
180		1254	20867		207	2											
200		2154	34592		344	15											
800		1248	20771		208	0											
840		234	3932		39	0											
																	
2.使用webbench的参数-c为2的指数增长，-t指定压测时长为10秒,但是这次用参数-f（不用等待服务器返回数据）对httpd再进行的测试																	
																	
		    Speed			    Request												
客户端		按每分钟	按每秒		success	failed											
2		6204	0		1034	0											
4		6318	0		1053	0											
8		6207	0		1045	0											
16		6324	0		1054	0											
32		6450	0		1075	0											
64		6942	0		1157	0											
128		13908	0		2318	0											
256		17328	0		2888	0											
512		38352	0		6392	0											
1024		9768	0		1628	0											
2048		24942	0		4157	0											
4096		28968	0		4828	0											
8192		29724	0		4954	0											
10000		28344	0		4724	0											
																	
																	
3.使用webbench的参数-c为2的指数增长，默认压测时长为30秒,-f（不等服务器返回数据）对httpd再次进行测试																	
																	
		     Speed			    Request												
客户端		按每分钟	按每秒		success	failed											
2		2100	0		1050	0											
4		2136	0		1068	0											
8		2150	0		1075	0											
16		2900	0		1450	0											
32		2506	0		1253	0											
64		6326	0		3163	0											
128		11368	0		5684	0											
256		10196	0		5098	0											
512		6636	0		3318	0											
1024		10508	0		5254	0											
2048		12556	0		6278	0											
4096		12810	0		6405	0											
8192		25232	0		12616	0											
 
结论 ：
    （1）由表一数据分析可得，该服务器在处理并发量不是很高的时候还是没有问题的，随着并发量的增加，该服务器处理的能力有所下降，而且性能不稳定；
    （2）由表二和表一对比来看，在不等待服务器返回数据的情况下，该服务器无论是从响应速率还是从响应成功的连接数来看都是比较稳定的，而且性能很好，到
        并发量较高时仍然可以处理，从这里就可以分析出服务器真正处理请求能力低下的原因在于创建新线程去处理请求需要耗费大量的时间和资源，在高并发时尤
        为突出；
    （3）由表三和表二对比可得，增加压力测试时长也会影响该服务器性能，从数据显示来看，前者的响应速率几乎时后者的三倍。
    
    总之，通过数据来看，在不等待服务器返回数据的时候服务器性能较好，但是等待服务器返回数据的时候性能会降低不少，而且带来性能不稳定的问题，由此我们可
     明白多线程版本的服务器，主线程监听，创建新线程去处理请求，在临时创建新线程的过程中会耗费戴良的时间，我们可以选择使用线程池来对其进行优化，也可以
     考虑协程来优化，协程是线程内部的一个执行流，这样可以节省不少资源，从而提升性能。 
